/Users/chunhaozou/Desktop/drl/envs/cartpole_train_eval.py:7: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import parse_requirements
name: __main__
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
/opt/miniconda3/envs/drl/lib/python3.11/site-packages/gymnasium/envs/classic_control/cartpole.py:214: UserWarning: [33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.[0m
  logger.warn(
Traceback (most recent call last):
  File "/Users/chunhaozou/Desktop/drl/envs/cartpole_train_eval.py", line 209, in <module>
    main()
  File "/Users/chunhaozou/Desktop/drl/envs/cartpole_train_eval.py", line 87, in main
    model.learn(total_timesteps=log_freq if total_timesteps_left >= log_freq else total_timesteps_left, log_interval=10)
  File "/opt/miniconda3/envs/drl/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/drl/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 323, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/drl/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/drl/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/drl/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/drl/lib/python3.11/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/chunhaozou/Desktop/drl/outputs/eureka/2024-12-08_20-06-48/env_iter0_response1.py", line 85, in step
    self.compute_reward()
  File "/Users/chunhaozou/Desktop/drl/outputs/eureka/2024-12-08_20-06-48/env_iter0_response1.py", line 69, in compute_reward
    self.reward, self.terminated, self.truncated, self.rew_dict = compute_reward(self.internal_state)
                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/chunhaozou/Desktop/drl/outputs/eureka/2024-12-08_20-06-48/env_iter0_response1.py", line 138, in compute_reward
    periodic_movement_reward = torch.exp(-periodic_movement_temperature * np.abs(cart_velocity))
                               ^^^^^
NameError: name 'torch' is not defined
